# Learnings from dag-factory (Astronomer)

`dag-factory` is a declarative YAML-based approach to creating Airflow DAGs. Below are the key takeaways we can apply to `dbt-factory` to make it more production-ready and user-friendly.

## 1. Layered Defaults (Hierarchical Configuration)
- **Concept**: `dag-factory` allows defining `default_args` at the top level, which are inherited by all DAGs/tasks unless overridden.
- **Dbt-factory Application**: We should implement a `defaults` block in `factory_config.yml` (e.g., default materialization, schema, or resource limits). This reduces boilerplate in the YAML.

## 2. Validation & Schema Enforcement
- **Concept**: Use of JSON Schema or Pydantic to validate the YAML before execution.
- **Dbt-factory Application**: Currently, `factory.py` assumes the YAML is perfect. We should add a validation step to catch missing templates or circular dependencies before invoking dbt.

## 3. Dynamic Task/Node Generation
- **Concept**: It treats every YAML block as a discrete task object with explicit dependencies (`dependencies: [task_a]`).
- **Dbt-factory Application**: Our current `generate_models` logic is a simple loop. We should transition to a graph-aware model where the factory understands the dbt DAG structure *before* writing files, allowing for smarter error checking.

## 4. Environment-Awareness
- **Concept**: `dag-factory` easily toggles between dev/prod via environment variables in the YAML (`!env_var`).
- **Dbt-factory Application**: Allow Jinja or environment variable injection into `factory_config.yml` so database targets (DuckDB vs BigQuery/Snowflake) can be swapped without changing the code.

## 5. Metadata Enrichment
- **Concept**: It automatically tags DAGs/Tasks with "generated-by: dag-factory".
- **Dbt-factory Application**: Every generated `.sql` file should have a header comment: `/* Generated by dbt-factory - DO NOT EDIT MANUALLY */`.
